# NLP

# ğŸ“Š Sentiment Analysis on Amazon Reviews

This project builds a complete text classification pipeline to analyze the sentiment of Amazon product reviews using different machine learning models.

[![Open in Colab] https://colab.research.google.com/drive/1BiukuRQH6uVcgEejz--nnC4VrjJyv14B#scrollTo=PyDmkvv15cna

---

## âœ… Project Overview

We implemented a sentiment analysis pipeline that includes:

- Data Preprocessing
- Feature Engineering (BoW, TF-IDF)
- Model Training (NaÃ¯ve Bayes, Logistic Regression, SVM)
- Evaluation & Comparison using Accuracy, Precision, Recall, and F1 Score
- Final Visualization of Model Metrics

---

## ğŸ“ˆ Model Comparison Results

| Model               | Accuracy | Precision | Recall | F1 Score |
|---------------------|----------|-----------|--------|----------|
| NaÃ¯ve Bayes         | 0.849    | 0.675     | 0.503  | 0.466    |
| Logistic Regression | 0.865    | 0.904     | 0.556  | 0.564    |
| SVM                 | 0.886    | 0.808     | 0.691  | 0.728    |

> âœ… **SVM outperformed other models**, delivering the highest F1 Score and overall accuracy.

---

## ğŸ§  Technologies Used

- Python
- Scikit-learn
- Pandas & NumPy
- Matplotlib & Seaborn
- Google Colab

---

## ğŸ› ï¸ How to Run

1. Click the "Open in Colab" button above
2. Run each cell in order
3. Review outputs and plots

---

## ğŸ” Key Takeaways

- Feature representation plays a crucial role in text classification.
- SVM is highly effective for sparse, high-dimensional data like TF-IDF features.
- Precision-Recall tradeoffs vary by model â€” choose based on use case (e.g., risk of false positives vs. false negatives).

---

## âœ¨ Future Improvements

- Add deep learning models (LSTM, BERT)
- Integrate Word Embeddings (Word2Vec, GloVe)
- Apply hyperparameter tuning (GridSearchCV)
